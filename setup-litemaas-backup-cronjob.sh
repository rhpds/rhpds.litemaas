#!/bin/bash
# =============================================================================
# LiteMaaS Backup Cronjob Setup
# =============================================================================
# Creates a cronjob on bastion that runs monthly to backup PostgreSQL and PVC to S3
#
# Usage:
#   ./setup-litemaas-backup-cronjob.sh <namespace> <s3-bucket>
#
# Examples:
#   ./setup-litemaas-backup-cronjob.sh litellm-rhpds my-backup-bucket
#
# What it does:
#   1. Creates a backup script on bastion at /usr/local/bin/backup-litemaas-<namespace>.sh
#   2. Sets up a monthly cronjob (runs on 1st at 2 AM)
#   3. The cronjob:
#      - Takes PostgreSQL pg_dump via oc exec
#      - Creates PVC snapshot using oc
#      - Uploads both to S3
#      - Maintains retention (keeps last 12 backups)
#
# Prerequisites:
#   - AWS CLI installed on bastion
#   - AWS credentials configured (~/.aws/credentials or environment variables)
#   - oc CLI authenticated to cluster
# =============================================================================

set -e

NAMESPACE="${1}"
S3_BUCKET="${2}"

if [ -z "$NAMESPACE" ] || [ -z "$S3_BUCKET" ]; then
    echo "Usage: $0 <namespace> <s3-bucket>"
    echo ""
    echo "Example:"
    echo "  $0 litellm-rhpds my-litemaas-backups"
    exit 1
fi

echo "========================================="
echo "LiteMaaS Backup Cronjob Setup"
echo "========================================="
echo "Namespace: $NAMESPACE"
echo "S3 Bucket: $S3_BUCKET"
echo ""

# Detect if we're running on bastion
if [[ "$(hostname)" == *"bastion"* ]] || [[ "$(hostname)" == *"utility"* ]]; then
    ON_BASTION=true
    echo "Detected: Running on bastion/utility node"
else
    ON_BASTION=false
    echo "Detected: Running from workstation (will use SSH)"
fi
echo ""

# Check if oc is available
if ! command -v oc &> /dev/null; then
    echo "ERROR: oc command not found. Please install OpenShift CLI."
    exit 1
fi

# Check if aws is available
if ! command -v aws &> /dev/null; then
    echo "ERROR: aws command not found. Please install AWS CLI."
    exit 1
fi

# Check if logged in
if ! oc whoami &> /dev/null; then
    echo "ERROR: Not logged into OpenShift. Run 'oc login' first."
    exit 1
fi

# Verify namespace exists
if ! oc get namespace "$NAMESPACE" &> /dev/null; then
    echo "ERROR: Namespace '$NAMESPACE' does not exist."
    exit 1
fi

# Check if PostgreSQL exists
if ! oc get statefulset litellm-postgres -n "$NAMESPACE" &> /dev/null; then
    echo "ERROR: PostgreSQL StatefulSet not found in namespace '$NAMESPACE'"
    exit 1
fi

echo "Creating backup script on bastion..."

# Create the backup script that will be installed on bastion
BACKUP_SCRIPT_CONTENT='#!/bin/bash
# Auto-generated by setup-litemaas-backup-cronjob.sh
# DO NOT EDIT MANUALLY - use setup script to regenerate

NAMESPACE="'"$NAMESPACE"'"
S3_BUCKET="'"$S3_BUCKET"'"
S3_PREFIX="litemaas-backups"
RETENTION_COUNT=12
LOGFILE="/var/log/litemaas-backup.log"
BACKUP_DIR="/tmp/litemaas-backup-$(date +%Y%m%d-%H%M%S)"

# Redirect all output to logfile
exec >> "$LOGFILE" 2>&1

echo "========================================="
echo "LiteMaaS Backup - $(date)"
echo "========================================="
echo "Namespace: $NAMESPACE"
echo "S3 Bucket: s3://${S3_BUCKET}/${S3_PREFIX}/"
echo "Backup Directory: $BACKUP_DIR"
echo ""

# Create backup directory
mkdir -p "$BACKUP_DIR"

# ============================================
# 1. PostgreSQL Backup (pg_dump via oc exec)
# ============================================
echo ">>> PostgreSQL backup starting..."

# Get PostgreSQL pod name
DB_POD=$(oc get pods -n "$NAMESPACE" -l app=litellm-postgres -o jsonpath='\''{.items[0].metadata.name}'\'')

if [ -z "$DB_POD" ]; then
    echo "ERROR: PostgreSQL pod not found"
    exit 1
fi

echo "Database pod: $DB_POD"

# Get database credentials from secret
DB_USER=$(oc get secret litemaas-db -n "$NAMESPACE" -o jsonpath='\''{.data.username}'\'' | base64 -d)
DB_PASSWORD=$(oc get secret litemaas-db -n "$NAMESPACE" -o jsonpath='\''{.data.password}'\'' | base64 -d)
DB_NAME=$(oc get secret litemaas-db -n "$NAMESPACE" -o jsonpath='\''{.data.database}'\'' | base64 -d)

echo "Database: $DB_NAME"
echo "Performing pg_dump..."

# Run pg_dump inside the PostgreSQL pod and save to bastion
oc exec "$DB_POD" -n "$NAMESPACE" -- bash -c \
  "PGPASSWORD='\''$DB_PASSWORD'\'' pg_dump -U $DB_USER -d $DB_NAME --clean --if-exists" \
  > "$BACKUP_DIR/database-$(date +%Y%m%d-%H%M%S).sql"

# Compress the SQL dump
gzip "$BACKUP_DIR/database-"*.sql

DB_BACKUP_FILE=$(ls "$BACKUP_DIR"/database-*.sql.gz)
DB_BACKUP_SIZE=$(du -h "$DB_BACKUP_FILE" | cut -f1)

echo "✓ Database backup created: $(basename $DB_BACKUP_FILE) ($DB_BACKUP_SIZE)"

# ============================================
# 2. PVC Backup (copy data via oc rsync)
# ============================================
echo ""
echo ">>> PVC backup starting..."

# Get PVC name
PVC_NAME=$(oc get pvc -n "$NAMESPACE" -l app=litellm-postgres -o jsonpath='\''{.items[0].metadata.name}'\'')

echo "PVC: $PVC_NAME"
echo "Copying PVC data via oc rsync..."

# Create temp directory for PVC data
PVC_BACKUP_DIR="$BACKUP_DIR/pvc-data"
mkdir -p "$PVC_BACKUP_DIR"

# Use oc rsync to copy data from PostgreSQL pod'\''s PVC
oc rsync "$DB_POD:/var/lib/postgresql/data/" "$PVC_BACKUP_DIR/" -n "$NAMESPACE"

# Tar and compress the PVC data
tar czf "$BACKUP_DIR/pvc-$(date +%Y%m%d-%H%M%S).tar.gz" -C "$PVC_BACKUP_DIR" .

# Remove the temp PVC directory
rm -rf "$PVC_BACKUP_DIR"

PVC_BACKUP_FILE=$(ls "$BACKUP_DIR"/pvc-*.tar.gz)
PVC_BACKUP_SIZE=$(du -h "$PVC_BACKUP_FILE" | cut -f1)

echo "✓ PVC backup created: $(basename $PVC_BACKUP_FILE) ($PVC_BACKUP_SIZE)"

# ============================================
# 3. Upload to S3
# ============================================
echo ""
echo ">>> Uploading backups to S3..."

# Upload database backup
aws s3 cp "$DB_BACKUP_FILE" "s3://${S3_BUCKET}/${S3_PREFIX}/$(basename $DB_BACKUP_FILE)"
echo "✓ Uploaded: $(basename $DB_BACKUP_FILE)"

# Upload PVC backup
aws s3 cp "$PVC_BACKUP_FILE" "s3://${S3_BUCKET}/${S3_PREFIX}/$(basename $PVC_BACKUP_FILE)"
echo "✓ Uploaded: $(basename $PVC_BACKUP_FILE)"

# ============================================
# 4. Cleanup Old Backups (retention policy)
# ============================================
echo ""
echo ">>> Cleaning up old backups..."
echo "Retention: Keep last $RETENTION_COUNT backups"

# Cleanup old database backups
DB_BACKUPS=$(aws s3 ls "s3://${S3_BUCKET}/${S3_PREFIX}/" | grep "database-" | sort -r | awk '\''{print $4}'\'')
DB_COUNT=$(echo "$DB_BACKUPS" | wc -l)

if [ "$DB_COUNT" -gt "$RETENTION_COUNT" ]; then
    OLD_DB_BACKUPS=$(echo "$DB_BACKUPS" | tail -n +$((RETENTION_COUNT + 1)))
    for backup in $OLD_DB_BACKUPS; do
        echo "Deleting old database backup: $backup"
        aws s3 rm "s3://${S3_BUCKET}/${S3_PREFIX}/$backup"
    done
else
    echo "Database backups: $DB_COUNT (within retention limit)"
fi

# Cleanup old PVC backups
PVC_BACKUPS=$(aws s3 ls "s3://${S3_BUCKET}/${S3_PREFIX}/" | grep "pvc-" | sort -r | awk '\''{print $4}'\'')
PVC_COUNT=$(echo "$PVC_BACKUPS" | wc -l)

if [ "$PVC_COUNT" -gt "$RETENTION_COUNT" ]; then
    OLD_PVC_BACKUPS=$(echo "$PVC_BACKUPS" | tail -n +$((RETENTION_COUNT + 1)))
    for backup in $OLD_PVC_BACKUPS; do
        echo "Deleting old PVC backup: $backup"
        aws s3 rm "s3://${S3_BUCKET}/${S3_PREFIX}/$backup"
    done
else
    echo "PVC backups: $PVC_COUNT (within retention limit)"
fi

# ============================================
# 5. Cleanup local backup directory
# ============================================
echo ""
echo ">>> Cleaning up local backup directory..."
rm -rf "$BACKUP_DIR"

# ============================================
# 6. Summary
# ============================================
echo ""
echo "========================================="
echo "Backup Complete - $(date)"
echo "========================================="
echo "Database backup: $DB_BACKUP_SIZE"
echo "PVC backup: $PVC_BACKUP_SIZE"
echo "S3 location: s3://${S3_BUCKET}/${S3_PREFIX}/"
echo ""
'

# Determine script path on bastion
SCRIPT_PATH="/usr/local/bin/backup-litemaas-${NAMESPACE}.sh"

if [ "$ON_BASTION" = true ]; then
    # Running on bastion - install directly
    echo "Installing backup script at: $SCRIPT_PATH"
    echo "$BACKUP_SCRIPT_CONTENT" | sudo tee "$SCRIPT_PATH" > /dev/null
    sudo chmod +x "$SCRIPT_PATH"

    # Create cron entry (monthly on 1st at 2 AM)
    CRON_ENTRY="0 2 1 * * $SCRIPT_PATH"

    # Check if cron entry already exists
    if crontab -l 2>/dev/null | grep -q "$SCRIPT_PATH"; then
        echo "Cronjob already exists. Updating..."
        (crontab -l 2>/dev/null | grep -v "$SCRIPT_PATH"; echo "$CRON_ENTRY") | crontab -
    else
        echo "Adding new cronjob..."
        (crontab -l 2>/dev/null; echo "$CRON_ENTRY") | crontab -
    fi

    echo ""
    echo "✓ Backup script installed: $SCRIPT_PATH"
    echo "✓ Cronjob configured: Monthly on 1st at 2 AM"
    echo ""
    echo "To run backup manually:"
    echo "  sudo $SCRIPT_PATH"
    echo ""
    echo "To view cronjobs:"
    echo "  crontab -l"
    echo ""
    echo "To view backup logs:"
    echo "  tail -f /var/log/litemaas-backup.log"

else
    # Running from workstation - provide manual instructions
    echo "========================================="
    echo "Manual Installation Required"
    echo "========================================="
    echo ""
    echo "Copy and run these commands on bastion:"
    echo ""
    echo "# 1. Create backup script"
    echo "cat > /tmp/backup-script.sh << 'EOFSCRIPT'"
    echo "$BACKUP_SCRIPT_CONTENT"
    echo "EOFSCRIPT"
    echo ""
    echo "sudo mv /tmp/backup-script.sh $SCRIPT_PATH"
    echo "sudo chmod +x $SCRIPT_PATH"
    echo ""
    echo "# 2. Add to crontab (monthly on 1st at 2 AM)"
    echo "(crontab -l 2>/dev/null; echo '0 2 1 * * $SCRIPT_PATH') | crontab -"
    echo ""
    echo "# 3. Test the backup script"
    echo "sudo $SCRIPT_PATH"
fi
