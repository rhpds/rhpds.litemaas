---
# =============================================================================
# RHOAI Metrics - Workload Tasks
# =============================================================================
# Deploy RHOAI User Workload Metrics and Grafana dashboards
# =============================================================================

# -----------------------------------------------------------------------------
# Step 1: Enable OpenShift User Workload Monitoring
# -----------------------------------------------------------------------------
- name: Check if User Workload Monitoring is enabled
  when: ocp4_workload_rhoai_metrics_enable_uwm | bool
  kubernetes.core.k8s_info:
    api_version: v1
    kind: ConfigMap
    name: cluster-monitoring-config
    namespace: openshift-monitoring
  register: r_cluster_monitoring_config

- name: Enable User Workload Monitoring
  when:
    - ocp4_workload_rhoai_metrics_enable_uwm | bool
    - r_cluster_monitoring_config.resources | length == 0 or
      'enableUserWorkload' not in (r_cluster_monitoring_config.resources[0].data['config.yaml'] | from_yaml).get('techPreviewUserWorkload', {})
  kubernetes.core.k8s:
    state: present
    definition:
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: cluster-monitoring-config
        namespace: openshift-monitoring
      data:
        config.yaml: |
          enableUserWorkload: true
          prometheusK8s:
            retention: {{ ocp4_workload_rhoai_metrics_uwm_retention }}

- name: Configure User Workload Monitoring retention
  when: ocp4_workload_rhoai_metrics_enable_uwm | bool
  kubernetes.core.k8s:
    state: present
    definition:
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: user-workload-monitoring-config
        namespace: openshift-user-workload-monitoring
      data:
        config.yaml: |
          prometheus:
            retention: {{ ocp4_workload_rhoai_metrics_uwm_retention }}

- name: Wait for User Workload Monitoring pods to be ready
  when: ocp4_workload_rhoai_metrics_enable_uwm | bool
  kubernetes.core.k8s_info:
    api_version: v1
    kind: Pod
    namespace: openshift-user-workload-monitoring
    label_selectors:
      - app.kubernetes.io/name=prometheus
  register: r_uwm_pods
  retries: 30
  delay: 10
  until:
    - r_uwm_pods.resources | length > 0
    - r_uwm_pods.resources | selectattr('status.phase', 'equalto', 'Running') | list | length > 0

# -----------------------------------------------------------------------------
# Step 2: Install Grafana Operator
# -----------------------------------------------------------------------------
- name: Create OperatorGroup for Grafana Operator
  when: ocp4_workload_rhoai_metrics_install_grafana_operator | bool
  kubernetes.core.k8s:
    state: present
    namespace: "{{ ocp4_workload_rhoai_metrics_namespace }}"
    definition:
      apiVersion: operators.coreos.com/v1
      kind: OperatorGroup
      metadata:
        name: grafana-operator-group
        namespace: "{{ ocp4_workload_rhoai_metrics_namespace }}"
      spec:
        targetNamespaces:
          - "{{ ocp4_workload_rhoai_metrics_namespace }}"

- name: Install Grafana Operator subscription
  when: ocp4_workload_rhoai_metrics_install_grafana_operator | bool
  kubernetes.core.k8s:
    state: present
    namespace: "{{ ocp4_workload_rhoai_metrics_namespace }}"
    definition: "{{ lookup('file', role_path + '/files/grafana/base/operator/subscription.yaml') | from_yaml }}"

- name: Wait for Grafana Operator to be ready
  when: ocp4_workload_rhoai_metrics_install_grafana_operator | bool
  kubernetes.core.k8s_info:
    api_version: v1
    kind: Pod
    namespace: "{{ ocp4_workload_rhoai_metrics_namespace }}"
    label_selectors:
      - control-plane=controller-manager
  register: r_grafana_operator_pods
  retries: 30
  delay: 10
  until:
    - r_grafana_operator_pods.resources | length > 0
    - r_grafana_operator_pods.resources | selectattr('status.phase', 'equalto', 'Running') | list | length > 0

# -----------------------------------------------------------------------------
# Step 3: Deploy Grafana Instance
# -----------------------------------------------------------------------------
- name: Create Grafana session secret
  when: ocp4_workload_rhoai_metrics_deploy_grafana | bool
  kubernetes.core.k8s:
    state: present
    namespace: "{{ ocp4_workload_rhoai_metrics_namespace }}"
    definition: "{{ lookup('file', role_path + '/files/grafana/base/instance/session-secret.yaml') | from_yaml }}"

- name: Create Grafana injected certs ConfigMap
  when: ocp4_workload_rhoai_metrics_deploy_grafana | bool
  kubernetes.core.k8s:
    state: present
    namespace: "{{ ocp4_workload_rhoai_metrics_namespace }}"
    definition: "{{ lookup('file', role_path + '/files/grafana/base/instance/injected-certs-cm.yaml') | from_yaml }}"

- name: Create Grafana proxy RBAC
  when: ocp4_workload_rhoai_metrics_deploy_grafana | bool
  kubernetes.core.k8s:
    state: present
    namespace: "{{ ocp4_workload_rhoai_metrics_namespace }}"
    definition: "{{ lookup('file', role_path + '/files/grafana/base/instance/grafana-proxy-rbac.yaml') | from_yaml }}"

- name: Create Grafana instance
  when: ocp4_workload_rhoai_metrics_deploy_grafana | bool
  kubernetes.core.k8s:
    state: present
    namespace: "{{ ocp4_workload_rhoai_metrics_namespace }}"
    definition: "{{ lookup('file', role_path + '/files/grafana/base/instance/grafana.yaml') | from_yaml }}"

# -----------------------------------------------------------------------------
# Step 4: Configure Grafana Datasources and Dashboards
# -----------------------------------------------------------------------------
- name: Create Grafana auth secret
  when: ocp4_workload_rhoai_metrics_deploy_grafana | bool
  kubernetes.core.k8s:
    state: present
    namespace: "{{ ocp4_workload_rhoai_metrics_namespace }}"
    definition: "{{ lookup('file', role_path + '/files/grafana/overlays/grafana-uwm-user-app/grafana-auth-secret.yaml') | from_yaml }}"

- name: Create cluster monitoring view RoleBinding
  when: ocp4_workload_rhoai_metrics_deploy_grafana | bool
  kubernetes.core.k8s:
    state: present
    namespace: "{{ ocp4_workload_rhoai_metrics_namespace }}"
    definition: "{{ lookup('file', role_path + '/files/grafana/overlays/grafana-uwm-user-app/cluster-monitor-view-rb.yaml') | from_yaml }}"

- name: Create Grafana datasource
  when: ocp4_workload_rhoai_metrics_deploy_grafana | bool
  kubernetes.core.k8s:
    state: present
    namespace: "{{ ocp4_workload_rhoai_metrics_namespace }}"
    definition: "{{ lookup('file', role_path + '/files/grafana/overlays/grafana-uwm-user-app/grafana-ds.yaml') | from_yaml }}"

# -----------------------------------------------------------------------------
# Step 4: Configure GPU Monitoring (if enabled)
# -----------------------------------------------------------------------------
- name: Check if NVIDIA GPU Operator is installed
  when: ocp4_workload_rhoai_metrics_enable_gpu | bool
  kubernetes.core.k8s_info:
    api_version: v1
    kind: Namespace
    name: "{{ ocp4_workload_rhoai_metrics_gpu_operator_namespace }}"
  register: r_gpu_operator_ns

- name: Enable DCGM Exporter metrics
  when:
    - ocp4_workload_rhoai_metrics_enable_gpu | bool
    - r_gpu_operator_ns.resources | length > 0
    - ocp4_workload_rhoai_metrics_dcgm_enabled | bool
  kubernetes.core.k8s:
    state: present
    definition:
      apiVersion: monitoring.coreos.com/v1
      kind: ServiceMonitor
      metadata:
        name: nvidia-dcgm-exporter
        namespace: "{{ ocp4_workload_rhoai_metrics_gpu_operator_namespace }}"
        labels:
          app: nvidia-dcgm-exporter
      spec:
        endpoints:
          - interval: "{{ ocp4_workload_rhoai_metrics_scrape_interval }}"
            port: metrics
            path: /metrics
            scheme: http
            timeout: "{{ ocp4_workload_rhoai_metrics_scrape_timeout }}"
        selector:
          matchLabels:
            app: nvidia-dcgm-exporter

# -----------------------------------------------------------------------------
# Step 5: Create ServiceMonitors for Model Serving (if enabled)
# -----------------------------------------------------------------------------
- name: Discover InferenceServices in namespace
  when: ocp4_workload_rhoai_metrics_enable_kserve | bool
  kubernetes.core.k8s_info:
    api_version: serving.kserve.io/v1beta1
    kind: InferenceService
    namespace: "{{ ocp4_workload_rhoai_metrics_namespace }}"
  register: r_inference_services

- name: Create ServiceMonitor for vLLM models
  when:
    - ocp4_workload_rhoai_metrics_enable_kserve | bool
    - "'vllm' in ocp4_workload_rhoai_metrics_runtimes"
  kubernetes.core.k8s:
    state: present
    definition:
      apiVersion: monitoring.coreos.com/v1
      kind: ServiceMonitor
      metadata:
        name: vllm-models
        namespace: "{{ ocp4_workload_rhoai_metrics_namespace }}"
        labels:
          app: vllm
      spec:
        endpoints:
          - interval: "{{ ocp4_workload_rhoai_metrics_scrape_interval }}"
            port: http
            path: "{{ ocp4_workload_rhoai_metrics_vllm_path }}"
            scheme: http
            timeout: "{{ ocp4_workload_rhoai_metrics_scrape_timeout }}"
        selector:
          matchLabels:
            serving.kserve.io/inferenceservice: "{{ item.metadata.name }}"
  loop: "{{ r_inference_services.resources }}"
  when: item.spec.predictor.model.runtimeVersion is defined and 'vllm' in item.spec.predictor.model.runtimeVersion | lower

- name: Create ServiceMonitor for OpenVino models
  when:
    - ocp4_workload_rhoai_metrics_enable_kserve | bool
    - "'openvino' in ocp4_workload_rhoai_metrics_runtimes"
  kubernetes.core.k8s:
    state: present
    definition:
      apiVersion: monitoring.coreos.com/v1
      kind: ServiceMonitor
      metadata:
        name: openvino-models
        namespace: "{{ ocp4_workload_rhoai_metrics_namespace }}"
        labels:
          app: openvino
      spec:
        endpoints:
          - interval: "{{ ocp4_workload_rhoai_metrics_scrape_interval }}"
            port: http
            path: "{{ ocp4_workload_rhoai_metrics_openvino_path }}"
            scheme: http
            timeout: "{{ ocp4_workload_rhoai_metrics_scrape_timeout }}"
        selector:
          matchLabels:
            serving.kserve.io/inferenceservice: "{{ item.metadata.name }}"
  loop: "{{ r_inference_services.resources }}"
  when: item.spec.predictor.model.runtimeVersion is defined and 'openvino' in item.spec.predictor.model.runtimeVersion | lower

# -----------------------------------------------------------------------------
# Step 6: Get Grafana Route
# -----------------------------------------------------------------------------
- name: Wait for Grafana route to be created
  when: ocp4_workload_rhoai_metrics_deploy_grafana | bool
  kubernetes.core.k8s_info:
    api_version: route.openshift.io/v1
    kind: Route
    name: "{{ ocp4_workload_rhoai_metrics_grafana_instance_name }}-route"
    namespace: "{{ ocp4_workload_rhoai_metrics_namespace }}"
  register: r_grafana_route
  retries: 30
  delay: 10
  until:
    - r_grafana_route.resources | length > 0
    - r_grafana_route.resources[0].spec.host is defined

- name: Display Grafana access information
  when:
    - ocp4_workload_rhoai_metrics_deploy_grafana | bool
    - r_grafana_route.resources | length > 0
  ansible.builtin.debug:
    msg:
      - "============================================"
      - "RHOAI Metrics Setup Complete!"
      - "============================================"
      - "Grafana URL: https://{{ r_grafana_route.resources[0].spec.host }}"
      - "Namespace: {{ ocp4_workload_rhoai_metrics_namespace }}"
      - "InferenceServices discovered: {{ r_inference_services.resources | length }}"
      - "============================================"

- name: Display completion message
  ansible.builtin.debug:
    msg:
      - "RHOAI User Workload Metrics enabled successfully"
      - "Grafana dashboards deployed for vLLM and OpenVino models"
      - "GPU monitoring: {{ 'enabled' if ocp4_workload_rhoai_metrics_enable_gpu else 'disabled' }}"
