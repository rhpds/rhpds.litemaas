---
# =============================================================================
# RHOAI Metrics - Workload Tasks
# =============================================================================
# Deploy RHOAI User Workload Metrics and Grafana dashboards
# =============================================================================

# -----------------------------------------------------------------------------
# Step 1: Enable OpenShift User Workload Monitoring
# -----------------------------------------------------------------------------
- name: Check if User Workload Monitoring is enabled
  when: ocp4_workload_rhoai_metrics_enable_uwm | bool
  kubernetes.core.k8s_info:
    api_version: v1
    kind: ConfigMap
    name: cluster-monitoring-config
    namespace: openshift-monitoring
  register: r_cluster_monitoring_config

- name: Enable User Workload Monitoring
  when:
    - ocp4_workload_rhoai_metrics_enable_uwm | bool
    - r_cluster_monitoring_config.resources | length == 0 or
      'enableUserWorkload' not in (r_cluster_monitoring_config.resources[0].data['config.yaml'] | from_yaml).get('techPreviewUserWorkload', {})
  kubernetes.core.k8s:
    state: present
    definition:
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: cluster-monitoring-config
        namespace: openshift-monitoring
      data:
        config.yaml: |
          enableUserWorkload: true
          prometheusK8s:
            retention: {{ ocp4_workload_rhoai_metrics_uwm_retention }}

- name: Configure User Workload Monitoring retention
  when: ocp4_workload_rhoai_metrics_enable_uwm | bool
  kubernetes.core.k8s:
    state: present
    definition:
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: user-workload-monitoring-config
        namespace: openshift-user-workload-monitoring
      data:
        config.yaml: |
          prometheus:
            retention: {{ ocp4_workload_rhoai_metrics_uwm_retention }}

- name: Wait for User Workload Monitoring pods to be ready
  when: ocp4_workload_rhoai_metrics_enable_uwm | bool
  kubernetes.core.k8s_info:
    api_version: v1
    kind: Pod
    namespace: openshift-user-workload-monitoring
    label_selectors:
      - app.kubernetes.io/name=prometheus
  register: r_uwm_pods
  retries: 30
  delay: 10
  until:
    - r_uwm_pods.resources | length > 0
    - r_uwm_pods.resources | selectattr('status.phase', 'equalto', 'Running') | list | length > 0

# -----------------------------------------------------------------------------
# Step 2: Install Grafana Operator
# -----------------------------------------------------------------------------
- name: Create OperatorGroup for Grafana Operator
  when: ocp4_workload_rhoai_metrics_install_grafana_operator | bool
  kubernetes.core.k8s:
    state: present
    namespace: "{{ ocp4_workload_rhoai_metrics_namespace }}"
    definition:
      apiVersion: operators.coreos.com/v1
      kind: OperatorGroup
      metadata:
        name: grafana-operator-group
        namespace: "{{ ocp4_workload_rhoai_metrics_namespace }}"
      spec:
        targetNamespaces:
          - "{{ ocp4_workload_rhoai_metrics_namespace }}"

- name: Install Grafana Operator subscription
  when: ocp4_workload_rhoai_metrics_install_grafana_operator | bool
  kubernetes.core.k8s:
    state: present
    namespace: "{{ ocp4_workload_rhoai_metrics_namespace }}"
    definition: "{{ lookup('file', role_path + '/files/grafana/base/operator/subscription.yaml') | from_yaml }}"

- name: Wait for Grafana Operator CSV to be Succeeded
  when: ocp4_workload_rhoai_metrics_install_grafana_operator | bool
  kubernetes.core.k8s_info:
    api_version: operators.coreos.com/v1alpha1
    kind: ClusterServiceVersion
    namespace: "{{ ocp4_workload_rhoai_metrics_namespace }}"
  register: r_grafana_csv
  retries: 30
  delay: 10
  until:
    - r_grafana_csv.resources | length > 0
    - r_grafana_csv.resources | selectattr('metadata.name', 'match', 'grafana-operator.*') | list | length > 0
    - r_grafana_csv.resources | selectattr('metadata.name', 'match', 'grafana-operator.*') | map(attribute='status.phase') | select('equalto', 'Succeeded') | list | length > 0

# -----------------------------------------------------------------------------
# Step 3: Deploy Grafana Instance
# -----------------------------------------------------------------------------
- name: Create Grafana session secret
  when: ocp4_workload_rhoai_metrics_deploy_grafana | bool
  kubernetes.core.k8s:
    state: present
    namespace: "{{ ocp4_workload_rhoai_metrics_namespace }}"
    definition: "{{ lookup('file', role_path + '/files/grafana/base/instance/session-secret.yaml') | from_yaml }}"

- name: Create Grafana injected certs ConfigMap
  when: ocp4_workload_rhoai_metrics_deploy_grafana | bool
  kubernetes.core.k8s:
    state: present
    namespace: "{{ ocp4_workload_rhoai_metrics_namespace }}"
    definition: "{{ lookup('file', role_path + '/files/grafana/base/instance/injected-certs-cm.yaml') | from_yaml }}"

- name: Create Grafana proxy RBAC
  when: ocp4_workload_rhoai_metrics_deploy_grafana | bool
  kubernetes.core.k8s:
    state: present
    namespace: "{{ ocp4_workload_rhoai_metrics_namespace }}"
    definition: "{{ lookup('file', role_path + '/files/grafana/base/instance/grafana-proxy-rbac.yaml') | from_yaml_all }}"

- name: Create Grafana instance with admin config
  when: ocp4_workload_rhoai_metrics_deploy_grafana | bool
  kubernetes.core.k8s:
    state: present
    namespace: "{{ ocp4_workload_rhoai_metrics_namespace }}"
    definition: "{{ lookup('file', role_path + '/files/grafana/base/instance/grafana.yaml') | from_yaml | combine({'spec': {'config': {'users': {'auto_assign_org': 'true', 'auto_assign_org_id': '1', 'auto_assign_org_role': 'Admin'}}}}, recursive=True) }}"

# -----------------------------------------------------------------------------
# Step 4: Configure Grafana Datasources and Dashboards
# -----------------------------------------------------------------------------
- name: Create Grafana service account
  when: ocp4_workload_rhoai_metrics_deploy_grafana | bool
  kubernetes.core.k8s:
    state: present
    namespace: "{{ ocp4_workload_rhoai_metrics_namespace }}"
    definition: "{{ lookup('file', role_path + '/files/grafana/base/instance/grafana-sa.yaml') | from_yaml }}"

- name: Create Grafana auth secret
  when: ocp4_workload_rhoai_metrics_deploy_grafana | bool
  kubernetes.core.k8s:
    state: present
    namespace: "{{ ocp4_workload_rhoai_metrics_namespace }}"
    definition: "{{ lookup('file', role_path + '/files/grafana/overlays/grafana-uwm-user-app/grafana-auth-secret.yaml') | from_yaml }}"

- name: Wait for auth secret to get token
  when: ocp4_workload_rhoai_metrics_deploy_grafana | bool
  kubernetes.core.k8s_info:
    api_version: v1
    kind: Secret
    name: grafana-auth-secret
    namespace: "{{ ocp4_workload_rhoai_metrics_namespace }}"
  register: r_auth_secret
  retries: 30
  delay: 2
  until:
    - r_auth_secret.resources | length > 0
    - r_auth_secret.resources[0].data.token is defined
    - r_auth_secret.resources[0].data.token | length > 0

- name: Create bearer token secret for datasource
  when: ocp4_workload_rhoai_metrics_deploy_grafana | bool
  kubernetes.core.k8s:
    state: present
    definition:
      apiVersion: v1
      kind: Secret
      metadata:
        name: grafana-bearer-token
        namespace: "{{ ocp4_workload_rhoai_metrics_namespace }}"
      type: Opaque
      stringData:
        bearer-token: "Bearer {{ r_auth_secret.resources[0].data.token | b64decode }}"

- name: Create cluster monitoring view ClusterRoleBinding
  when: ocp4_workload_rhoai_metrics_deploy_grafana | bool
  kubernetes.core.k8s:
    state: present
    definition: "{{ lookup('file', role_path + '/files/grafana/overlays/grafana-uwm-user-app/cluster-monitor-view-rb.yaml') | from_yaml | combine({'subjects': [{'kind': 'ServiceAccount', 'name': 'grafana-sa', 'namespace': ocp4_workload_rhoai_metrics_namespace}]}, recursive=True) }}"

- name: Create Grafana datasource
  when: ocp4_workload_rhoai_metrics_deploy_grafana | bool
  kubernetes.core.k8s:
    state: present
    namespace: "{{ ocp4_workload_rhoai_metrics_namespace }}"
    definition: "{{ lookup('file', role_path + '/files/grafana/overlays/grafana-uwm-user-app/grafana-ds.yaml') | from_yaml }}"

# -----------------------------------------------------------------------------
# Step 4a: Grant Grafana admin permissions
# -----------------------------------------------------------------------------
- name: Create Grafana admin RoleBinding
  when: ocp4_workload_rhoai_metrics_deploy_grafana | bool
  kubernetes.core.k8s:
    state: present
    definition:
      apiVersion: rbac.authorization.k8s.io/v1
      kind: RoleBinding
      metadata:
        name: grafana-admin
        namespace: "{{ ocp4_workload_rhoai_metrics_namespace }}"
      roleRef:
        apiGroup: rbac.authorization.k8s.io
        kind: ClusterRole
        name: admin
      subjects:
        - apiGroup: rbac.authorization.k8s.io
          kind: User
          name: psrivast
        - apiGroup: rbac.authorization.k8s.io
          kind: User
          name: ajammula
        - apiGroup: rbac.authorization.k8s.io
          kind: User
          name: brezhnev
        - apiGroup: rbac.authorization.k8s.io
          kind: User
          name: rshah
        - apiGroup: rbac.authorization.k8s.io
          kind: User
          name: oczernin

# -----------------------------------------------------------------------------
# Step 4b: Deploy Grafana Dashboards
# -----------------------------------------------------------------------------
- name: Create Grafana folder for dashboards
  when: ocp4_workload_rhoai_metrics_deploy_grafana | bool
  kubernetes.core.k8s:
    state: present
    namespace: "{{ ocp4_workload_rhoai_metrics_namespace }}"
    definition: "{{ lookup('file', role_path + '/files/grafana/overlays/rhoai-uwm-user-grafana-app/grafana-folder.yaml') | from_yaml }}"

- name: Deploy vLLM dashboard
  when: ocp4_workload_rhoai_metrics_deploy_grafana | bool
  kubernetes.core.k8s:
    state: present
    namespace: "{{ ocp4_workload_rhoai_metrics_namespace }}"
    definition: "{{ lookup('file', role_path + '/files/grafana/overlays/rhoai-uwm-user-grafana-app/grafana-vllm-dashboard.yaml') | from_yaml }}"

- name: Deploy NVIDIA vLLM dashboard
  when:
    - ocp4_workload_rhoai_metrics_deploy_grafana | bool
    - ocp4_workload_rhoai_metrics_enable_gpu | bool
  kubernetes.core.k8s:
    state: present
    namespace: "{{ ocp4_workload_rhoai_metrics_namespace }}"
    definition: "{{ lookup('file', role_path + '/files/grafana/overlays/rhoai-uwm-user-grafana-app/nvidia-vllm-dashboard.yaml') | from_yaml }}"

- name: Deploy OpenVino dashboard
  when: ocp4_workload_rhoai_metrics_deploy_grafana | bool
  kubernetes.core.k8s:
    state: present
    namespace: "{{ ocp4_workload_rhoai_metrics_namespace }}"
    definition: "{{ lookup('file', role_path + '/files/grafana/overlays/rhoai-uwm-user-grafana-app/grafana-ovms-dashboard.yaml') | from_yaml }}"

# -----------------------------------------------------------------------------
# Step 5: Configure GPU Monitoring (if enabled)
# -----------------------------------------------------------------------------
- name: Check if NVIDIA GPU Operator is installed
  when: ocp4_workload_rhoai_metrics_enable_gpu | bool
  kubernetes.core.k8s_info:
    api_version: v1
    kind: Namespace
    name: "{{ ocp4_workload_rhoai_metrics_gpu_operator_namespace }}"
  register: r_gpu_operator_ns

- name: Enable DCGM Exporter metrics
  when:
    - ocp4_workload_rhoai_metrics_enable_gpu | bool
    - r_gpu_operator_ns.resources | length > 0
    - ocp4_workload_rhoai_metrics_dcgm_enabled | bool
  kubernetes.core.k8s:
    state: present
    definition:
      apiVersion: monitoring.coreos.com/v1
      kind: ServiceMonitor
      metadata:
        name: nvidia-dcgm-exporter
        namespace: "{{ ocp4_workload_rhoai_metrics_gpu_operator_namespace }}"
        labels:
          app: nvidia-dcgm-exporter
      spec:
        endpoints:
          - interval: "{{ ocp4_workload_rhoai_metrics_scrape_interval }}"
            port: metrics
            path: /metrics
            scheme: http
            timeout: "{{ ocp4_workload_rhoai_metrics_scrape_timeout }}"
        selector:
          matchLabels:
            app: nvidia-dcgm-exporter

# -----------------------------------------------------------------------------
# Step 6: Create ServiceMonitors for Model Serving (if enabled)
# -----------------------------------------------------------------------------
- name: Discover InferenceServices in namespace
  when: ocp4_workload_rhoai_metrics_enable_kserve | bool
  kubernetes.core.k8s_info:
    api_version: serving.kserve.io/v1beta1
    kind: InferenceService
    namespace: "{{ ocp4_workload_rhoai_metrics_namespace }}"
  register: r_inference_services

- name: Create ServiceMonitor for vLLM models
  when:
    - ocp4_workload_rhoai_metrics_enable_kserve | bool
    - "'vllm' in ocp4_workload_rhoai_metrics_runtimes"
  kubernetes.core.k8s:
    state: present
    definition:
      apiVersion: monitoring.coreos.com/v1
      kind: ServiceMonitor
      metadata:
        name: vllm-models
        namespace: "{{ ocp4_workload_rhoai_metrics_namespace }}"
        labels:
          app: vllm
      spec:
        endpoints:
          - interval: "{{ ocp4_workload_rhoai_metrics_scrape_interval }}"
            port: http
            path: "{{ ocp4_workload_rhoai_metrics_vllm_path }}"
            scheme: http
            timeout: "{{ ocp4_workload_rhoai_metrics_scrape_timeout }}"
        selector:
          matchLabels:
            serving.kserve.io/inferenceservice: "{{ item.metadata.name }}"
  loop: "{{ r_inference_services.resources }}"
  when: >
    (item.spec.predictor.model.modelFormat.name is defined and item.spec.predictor.model.modelFormat.name | lower == 'vllm') or
    (item.spec.predictor.model.runtimeVersion is defined and 'vllm' in item.spec.predictor.model.runtimeVersion | lower) or
    (item.spec.predictor.model.runtime is defined and 'vllm' in item.spec.predictor.model.runtime | lower)

- name: Create ServiceMonitor for OpenVino models
  when:
    - ocp4_workload_rhoai_metrics_enable_kserve | bool
    - "'openvino' in ocp4_workload_rhoai_metrics_runtimes"
  kubernetes.core.k8s:
    state: present
    definition:
      apiVersion: monitoring.coreos.com/v1
      kind: ServiceMonitor
      metadata:
        name: openvino-models
        namespace: "{{ ocp4_workload_rhoai_metrics_namespace }}"
        labels:
          app: openvino
      spec:
        endpoints:
          - interval: "{{ ocp4_workload_rhoai_metrics_scrape_interval }}"
            port: http
            path: "{{ ocp4_workload_rhoai_metrics_openvino_path }}"
            scheme: http
            timeout: "{{ ocp4_workload_rhoai_metrics_scrape_timeout }}"
        selector:
          matchLabels:
            serving.kserve.io/inferenceservice: "{{ item.metadata.name }}"
  loop: "{{ r_inference_services.resources }}"
  when: >
    (item.spec.predictor.model.modelFormat.name is defined and item.spec.predictor.model.modelFormat.name | lower == 'openvino') or
    (item.spec.predictor.model.runtimeVersion is defined and 'openvino' in item.spec.predictor.model.runtimeVersion | lower) or
    (item.spec.predictor.model.runtime is defined and 'openvino' in item.spec.predictor.model.runtime | lower)

# -----------------------------------------------------------------------------
# Step 7: Get Grafana Route
# -----------------------------------------------------------------------------
- name: Wait for Grafana route to be created
  when: ocp4_workload_rhoai_metrics_deploy_grafana | bool
  kubernetes.core.k8s_info:
    api_version: route.openshift.io/v1
    kind: Route
    name: grafana-route
    namespace: "{{ ocp4_workload_rhoai_metrics_namespace }}"
  register: r_grafana_route
  retries: 30
  delay: 10
  until:
    - r_grafana_route.resources | length > 0
    - r_grafana_route.resources[0].spec.host is defined

- name: Display Grafana access information
  when:
    - ocp4_workload_rhoai_metrics_deploy_grafana | bool
    - r_grafana_route.resources | length > 0
  ansible.builtin.debug:
    msg:
      - "============================================"
      - "RHOAI Metrics Setup Complete!"
      - "============================================"
      - "Grafana URL: https://{{ r_grafana_route.resources[0].spec.host }}"
      - "Namespace: {{ ocp4_workload_rhoai_metrics_namespace }}"
      - "InferenceServices discovered: {{ r_inference_services.resources | length }}"
      - "============================================"

- name: Display completion message
  ansible.builtin.debug:
    msg:
      - "RHOAI User Workload Metrics enabled successfully"
      - "Grafana dashboards deployed for vLLM and OpenVino models"
      - "GPU monitoring: {{ 'enabled' if ocp4_workload_rhoai_metrics_enable_gpu else 'disabled' }}"
