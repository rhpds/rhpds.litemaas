<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LiteMaaS Benchmark Results - {{ guid }}</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Red Hat Display', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: #333;
            padding: 20px;
            min-height: 100vh;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            background: white;
            border-radius: 12px;
            box-shadow: 0 20px 60px rgba(0,0,0,0.3);
            overflow: hidden;
        }

        .header {
            background: linear-gradient(135deg, #ee0000 0%, #c00000 100%);
            color: white;
            padding: 40px;
            text-align: center;
        }

        .header h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
            font-weight: 300;
        }

        .header .guid {
            font-size: 1.2em;
            opacity: 0.9;
            font-family: 'Red Hat Mono', monospace;
        }

        .download-button {
            display: inline-block;
            margin-top: 20px;
            padding: 12px 30px;
            background: white;
            color: #ee0000;
            border: none;
            border-radius: 6px;
            font-size: 1.1em;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s;
            text-decoration: none;
        }

        .download-button:hover {
            background: #f5f5f5;
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0,0,0,0.2);
        }

        .status-banner {
            padding: 30px;
            text-align: center;
            font-size: 2em;
            font-weight: bold;
        }

        .status-banner.pass {
            background: #22c55e;
            color: white;
        }

        .status-banner.warn {
            background: #f59e0b;
            color: white;
        }

        .status-banner.fail {
            background: #ef4444;
            color: white;
        }

        .metrics {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px;
            padding: 40px;
        }

        .metric-card {
            background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
            padding: 25px;
            border-radius: 8px;
            border-left: 4px solid #ee0000;
        }

        .metric-card.highlight {
            background: linear-gradient(135deg, #ffeaa7 0%, #fdcb6e 100%);
            border-left-color: #e17055;
        }

        .metric-label {
            font-size: 0.9em;
            color: #666;
            margin-bottom: 8px;
            text-transform: uppercase;
            letter-spacing: 1px;
        }

        .metric-value {
            font-size: 2.5em;
            font-weight: bold;
            color: #333;
        }

        .metric-unit {
            font-size: 0.5em;
            color: #666;
            margin-left: 5px;
        }

        .section {
            padding: 40px;
            border-top: 1px solid #e5e7eb;
        }

        .section h2 {
            font-size: 1.8em;
            margin-bottom: 20px;
            color: #ee0000;
        }

        .config-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 15px;
            margin-top: 20px;
        }

        .config-item {
            background: #f9fafb;
            padding: 15px;
            border-radius: 6px;
        }

        .config-item strong {
            display: block;
            color: #666;
            font-size: 0.85em;
            margin-bottom: 5px;
        }

        .config-item span {
            font-size: 1.3em;
            color: #333;
        }

        .raw-output {
            background: #1e293b;
            color: #e2e8f0;
            padding: 20px;
            border-radius: 8px;
            overflow-x: auto;
            font-family: 'Red Hat Mono', 'Courier New', monospace;
            font-size: 0.9em;
            line-height: 1.6;
            max-height: 600px;
            overflow-y: auto;
        }

        .interpretation {
            background: #f0f9ff;
            border-left: 4px solid #3b82f6;
            padding: 20px;
            margin-top: 20px;
            border-radius: 4px;
        }

        .interpretation h3 {
            color: #1e40af;
            margin-bottom: 15px;
        }

        .interpretation ul {
            list-style: none;
            padding-left: 0;
        }

        .interpretation li {
            padding: 8px 0;
            display: flex;
            align-items: center;
        }

        .interpretation li::before {
            content: "â†’";
            color: #3b82f6;
            font-weight: bold;
            margin-right: 10px;
        }

        .badge {
            display: inline-block;
            padding: 4px 12px;
            border-radius: 12px;
            font-size: 0.85em;
            font-weight: 600;
            margin-left: 10px;
        }

        .badge.excellent {
            background: #22c55e;
            color: white;
        }

        .badge.good {
            background: #3b82f6;
            color: white;
        }

        .badge.poor {
            background: #ef4444;
            color: white;
        }

        .footer {
            background: #f9fafb;
            padding: 30px;
            text-align: center;
            color: #666;
            font-size: 0.9em;
        }

        .timestamp {
            color: #999;
            font-size: 0.85em;
            margin-top: 10px;
        }

        /* Print styles for PDF export */
        @media print {
            body {
                background: white;
                padding: 0;
            }

            .container {
                box-shadow: none;
                border-radius: 0;
            }

            .download-button {
                display: none;
            }

            .section {
                page-break-inside: avoid;
            }

            .raw-output {
                max-height: none;
                page-break-inside: avoid;
            }
        }
    </style>
    <script>
        function downloadPDF() {
            window.print();
        }
    </script>
</head>
<body>
    <div class="container">
        <!-- Header -->
        <div class="header">
            <h1>LiteMaaS Benchmark Results</h1>
            <div class="guid">Environment: {{ guid }}</div>
            <button class="download-button" onclick="downloadPDF()">ðŸ“„ Download as PDF</button>
        </div>

        <!-- Status Banner -->
        <div class="status-banner {{ 'pass' if benchmark_status == 'PASS âœ“' else 'warn' if benchmark_status == 'WARN âš ' else 'fail' }}">
            Overall Status: {{ benchmark_status }}
        </div>

        <!-- Summary Recommendation -->
        <div class="section">
            <h2>ðŸ“‹ Capacity Summary</h2>

            {% if benchmark_p95 != 'N/A' and benchmark_p95 | float < 500 %}
            <div class="interpretation" style="background: #d1fae5; border-left-color: #10b981;">
                <h3 style="color: #065f46;">âœ“ Your LiteMaaS Deployment Can Handle This Load</h3>
                <p><strong>Tested Configuration:</strong></p>
                <ul>
                    <li>{{ ocp4_workload_litemaas_benchmark_conversations }} concurrent users</li>
                    <li>{{ ocp4_workload_litemaas_benchmark_turns }} queries per user</li>
                    <li>P95 response time: {{ benchmark_p95 }} ms (excellent - under 500ms threshold)</li>
                </ul>
                <p><strong>Recommendation:</strong></p>
                <ul>
                    <li>âœ“ This model is ready for your workshop</li>
                    <li>âœ“ Can handle {{ ocp4_workload_litemaas_benchmark_conversations }} learners working simultaneously</li>
                    <li>âœ“ Response times are fast enough for good user experience</li>
                    {% if benchmark_speedup != 'N/A' and benchmark_speedup | float > 3 %}
                    <li>âœ“ Prefix caching is working excellently ({{ benchmark_speedup }}x speedup)</li>
                    {% endif %}
                </ul>
            </div>
            {% elif benchmark_p95 != 'N/A' and benchmark_p95 | float < 1000 %}
            <div class="interpretation" style="background: #fef3c7; border-left-color: #f59e0b;">
                <h3 style="color: #92400e;">âš  Acceptable Performance - Monitor Closely</h3>
                <p><strong>Tested Configuration:</strong></p>
                <ul>
                    <li>{{ ocp4_workload_litemaas_benchmark_conversations }} concurrent users</li>
                    <li>{{ ocp4_workload_litemaas_benchmark_turns }} queries per user</li>
                    <li>P95 response time: {{ benchmark_p95 }} ms (acceptable but not ideal)</li>
                </ul>
                <p><strong>Recommendation:</strong></p>
                <ul>
                    <li>âš  This deployment can handle {{ ocp4_workload_litemaas_benchmark_conversations }} users, but performance is at limit</li>
                    <li>âš  Consider reducing expected attendees by 20-30% for better experience</li>
                    <li>âš  Monitor actual workshop performance closely</li>
                    <li>Alternative: Reduce max_tokens or conversation complexity</li>
                </ul>
            </div>
            {% else %}
            <div class="interpretation" style="background: #fee2e2; border-left-color: #ef4444;">
                <h3 style="color: #991b1b;">âœ— This Deployment Cannot Handle This Load</h3>
                <p><strong>Tested Configuration:</strong></p>
                <ul>
                    <li>{{ ocp4_workload_litemaas_benchmark_conversations }} concurrent users</li>
                    <li>{{ ocp4_workload_litemaas_benchmark_turns }} queries per user</li>
                    <li>P95 response time: {{ benchmark_p95 }} ms (too slow - exceeds 1000ms threshold)</li>
                </ul>
                <p><strong>Recommendation:</strong></p>
                <ul>
                    <li>âœ— DO NOT run workshop with {{ ocp4_workload_litemaas_benchmark_conversations }} concurrent users</li>
                    <li>âœ— Response times are too slow for acceptable user experience</li>
                    <li><strong>Action Required:</strong> Reduce to {{ (ocp4_workload_litemaas_benchmark_conversations | int * 0.5) | int }} users and re-test</li>
                    <li>OR: Switch to a smaller/faster model</li>
                    <li>OR: Reduce max_tokens and conversation complexity</li>
                </ul>
            </div>
            {% endif %}

            {% if benchmark_speedup != 'N/A' and benchmark_speedup | float < 2 %}
            <div class="interpretation" style="background: #fee2e2; border-left-color: #ef4444; margin-top: 20px;">
                <h3 style="color: #991b1b;">âš  Warning: Poor Prefix Caching Performance</h3>
                <ul>
                    <li>Speedup ratio: {{ benchmark_speedup }}x (below 2x threshold)</li>
                    <li>This means the KV cache is not working effectively</li>
                    <li>Multi-turn conversations will be slower than expected</li>
                    <li><strong>Check:</strong> Does this model support prefix caching?</li>
                    <li><strong>Check:</strong> Is context size too large for effective caching?</li>
                </ul>
            </div>
            {% endif %}
        </div>

        <!-- Key Metrics -->
        <div class="metrics">
            <div class="metric-card highlight">
                <div class="metric-label">P95 TTFT</div>
                <div class="metric-value">{{ benchmark_p95 }}<span class="metric-unit">ms</span></div>
            </div>

            <div class="metric-card">
                <div class="metric-label">P50 (Median)</div>
                <div class="metric-value">{{ benchmark_p50 }}<span class="metric-unit">ms</span></div>
            </div>

            <div class="metric-card">
                <div class="metric-label">Mean TTFT</div>
                <div class="metric-value">{{ benchmark_mean }}<span class="metric-unit">ms</span></div>
            </div>

            <div class="metric-card">
                <div class="metric-label">P99 TTFT</div>
                <div class="metric-value">{{ benchmark_p99 }}<span class="metric-unit">ms</span></div>
            </div>
        </div>

        <!-- Cache Performance -->
        <div class="section">
            <h2>Cache Performance <span class="badge {{ 'excellent' if 'EXCELLENT' in benchmark_cache_status else 'good' if 'GOOD' in benchmark_cache_status else 'poor' }}">{{ benchmark_cache_status }}</span></h2>

            <div class="metrics">
                <div class="metric-card highlight">
                    <div class="metric-label">Speedup Ratio</div>
                    <div class="metric-value">{{ benchmark_speedup }}<span class="metric-unit">x</span></div>
                </div>
            </div>

            <div class="interpretation">
                <h3>What does this mean?</h3>
                <ul>
                    <li><strong>Speedup Ratio:</strong> How much faster later turns are vs the first turn</li>
                    <li>&gt; 3x = Excellent prefix caching (cached context reused effectively)</li>
                    <li>&gt; 2x = Good prefix caching</li>
                    <li>&lt; 2x = Poor cache effectiveness (may need optimization)</li>
                </ul>
            </div>
        </div>

        <!-- Load Testing Results -->
        <div class="section">
            <h2>Load Testing Results</h2>

            <div class="config-grid">
                <div class="config-item">
                    <strong>Total Time</strong>
                    <span>{{ benchmark_total_time }} seconds</span>
                </div>
                <div class="config-item">
                    <strong>Total Requests</strong>
                    <span>{{ benchmark_total_requests }}</span>
                </div>
                <div class="config-item">
                    <strong>Requests/Second</strong>
                    <span>{{ benchmark_rps }}</span>
                </div>
            </div>
        </div>

        <!-- Test Configuration -->
        <div class="section">
            <h2>Test Configuration</h2>

            <div class="config-grid">
                <div class="config-item">
                    <strong>Attendees Per Session</strong>
                    <span>{{ ocp4_workload_litemaas_benchmark_conversations }}</span>
                </div>
                <div class="config-item">
                    <strong>Number of Sessions</strong>
                    <span>{{ ocp4_workload_litemaas_benchmark_sessions }}</span>
                </div>
                <div class="config-item">
                    <strong>Questions Per Person</strong>
                    <span>{{ ocp4_workload_litemaas_benchmark_turns }}</span>
                </div>
                {% if ocp4_workload_litemaas_benchmark_mcp_enabled | default(false) | bool %}
                <div class="config-item">
                    <strong>Tool Calling (MCP)</strong>
                    <span>âœ“ Enabled</span>
                </div>
                <div class="config-item">
                    <strong>Multiplier Applied</strong>
                    <span>3x ({{ ocp4_workload_litemaas_benchmark_turns }} Ã— 3 = {{ litemaas_benchmark_effective_turns | default(ocp4_workload_litemaas_benchmark_turns | int * 3) }})</span>
                </div>
                <div class="config-item">
                    <strong>Effective Test Queries</strong>
                    <span>{{ litemaas_benchmark_effective_turns | default(ocp4_workload_litemaas_benchmark_turns | int * 3) }}</span>
                </div>
                {% endif %}
                <div class="config-item">
                    <strong>Parallel Workers</strong>
                    <span>{{ litemaas_benchmark_parallel_workers }}</span>
                </div>
                <div class="config-item">
                    <strong>Max Tokens</strong>
                    <span>{{ ocp4_workload_litemaas_benchmark_max_tokens }}</span>
                </div>
            </div>
        </div>

        <!-- How This Test Works -->
        <div class="section">
            <h2>ðŸ“š How This Test Works</h2>

            <div class="interpretation">
                <h3>What Did We Just Test?</h3>
                <p>This benchmark simulates a real workshop scenario to validate if your LiteMaaS deployment can handle the expected load.</p>

                <ul>
                    <li><strong>Your Workshop Setup:</strong></li>
                    <li style="margin-left: 20px;">â€¢ {{ ocp4_workload_litemaas_benchmark_conversations }} people attend each session</li>
                    <li style="margin-left: 20px;">â€¢ {{ ocp4_workload_litemaas_benchmark_sessions }} session(s) per day</li>
                    <li style="margin-left: 20px;">â€¢ Each person asks ~{{ ocp4_workload_litemaas_benchmark_turns }} questions</li>
                    {% if ocp4_workload_litemaas_benchmark_mcp_enabled | default(false) | bool %}
                    <li style="margin-left: 20px;">â€¢ LibreChat/MCP tool calling enabled (3x multiplier applied)</li>
                    {% endif %}
                </ul>

                <ul>
                    <li><strong>What We Tested:</strong></li>
                    <li style="margin-left: 20px;">â€¢ Created {{ ocp4_workload_litemaas_benchmark_conversations }} simulated users (fake people)</li>
                    <li style="margin-left: 20px;">â€¢ Each fake person asked {{ litemaas_benchmark_effective_turns | default(ocp4_workload_litemaas_benchmark_turns) }} questions to the AI</li>
                    <li style="margin-left: 20px;">â€¢ {{ litemaas_benchmark_parallel_workers }} people asking questions at the same time (like a queue)</li>
                    <li style="margin-left: 20px;">â€¢ Total test queries: {{ ocp4_workload_litemaas_benchmark_conversations }} Ã— {{ litemaas_benchmark_effective_turns | default(ocp4_workload_litemaas_benchmark_turns) }} = {{ ocp4_workload_litemaas_benchmark_conversations | int * (litemaas_benchmark_effective_turns | default(ocp4_workload_litemaas_benchmark_turns) | int) }}</li>
                </ul>

                <ul>
                    <li><strong>Parallel Workers Explained:</strong></li>
                    <li style="margin-left: 20px;">â€¢ Not all {{ ocp4_workload_litemaas_benchmark_conversations }} people ask questions at the exact same moment</li>
                    <li style="margin-left: 20px;">â€¢ In real workshops, maybe 4-8 people are actively typing at any second</li>
                    <li style="margin-left: 20px;">â€¢ We used {{ litemaas_benchmark_parallel_workers }} parallel workers to simulate realistic load</li>
                    <li style="margin-left: 20px;">â€¢ Think of it like: {{ litemaas_benchmark_parallel_workers }} checkout lanes at a store for {{ ocp4_workload_litemaas_benchmark_conversations }} customers</li>
                </ul>

                {% if ocp4_workload_litemaas_benchmark_mcp_enabled | default(false) | bool %}
                <ul>
                    <li><strong>Why the 3x Multiplier?</strong></li>
                    <li style="margin-left: 20px;">â€¢ LibreChat/MCP workshops use tool calling (AI can invoke functions/tools)</li>
                    <li style="margin-left: 20px;">â€¢ Each user question might trigger 2-3 additional AI requests</li>
                    <li style="margin-left: 20px;">â€¢ Example: User asks "deploy an app" â†’ AI calls tool to check cluster â†’ calls tool to deploy â†’ responds to user</li>
                    <li style="margin-left: 20px;">â€¢ Your {{ ocp4_workload_litemaas_benchmark_turns }} questions became {{ litemaas_benchmark_effective_turns | default(ocp4_workload_litemaas_benchmark_turns | int * 3) }} actual AI requests in the test</li>
                </ul>
                {% endif %}
            </div>

            <div class="interpretation">
                <h3>Auto-Calculated Settings</h3>
                <p>The system automatically adjusted some settings based on your configuration:</p>
                <ul>
                    <li><strong>Parallel Workers:</strong> {{ litemaas_benchmark_parallel_workers }}</li>
                    <li style="margin-left: 20px;">â€¢ Auto-calculated based on {{ ocp4_workload_litemaas_benchmark_conversations }} attendees</li>
                    <li style="margin-left: 20px;">â€¢ 1-30 people = 2 workers | 31-60 people = 4 workers | 61-100 people = 8 workers | 101+ = 16 workers</li>

                    {% if ocp4_workload_litemaas_benchmark_mcp_enabled | default(false) | bool %}
                    <li><strong>Effective Queries:</strong> {{ litemaas_benchmark_effective_turns | default(ocp4_workload_litemaas_benchmark_turns | int * 3) }}</li>
                    <li style="margin-left: 20px;">â€¢ Auto-calculated: {{ ocp4_workload_litemaas_benchmark_turns }} base questions Ã— 3 (MCP multiplier)</li>
                    <li style="margin-left: 20px;">â€¢ Accounts for tool calling creating additional AI requests</li>
                    {% endif %}
                </ul>
            </div>
        </div>

        <!-- Performance Interpretation -->
        <div class="section">
            <h2>Understanding Your Results</h2>

            <div class="interpretation">
                <h3>What Do These Metrics Mean?</h3>
                <ul>
                    <li><strong>P50 (Median):</strong> Half of requests were faster than this</li>
                    <li><strong>P95:</strong> 95% of requests were faster (key metric for user experience)</li>
                    <li><strong>P99:</strong> 99% of requests were faster (catches outliers)</li>
                    <li><strong>Speedup Ratio:</strong> How much faster later turns are vs the first turn</li>
                    <li>Higher speedup = Better prefix caching (compares first turn vs cached turns)</li>
                </ul>
            </div>

            <div class="interpretation">
                <h3>TTFT Performance Thresholds</h3>
                <ul>
                    <li><strong>P95 &lt; 500ms:</strong> Excellent user experience âœ“</li>
                    <li><strong>P95 500-1000ms:</strong> Good user experience</li>
                    <li><strong>P95 &gt; 1000ms:</strong> May need optimization âœ—</li>
                </ul>
            </div>

            <div class="interpretation">
                <h3>What Should I Do With These Results?</h3>
                <ul>
                    <li><strong>P95 &lt; 500ms:</strong> Excellent! Your configuration can handle this load.</li>
                    <li><strong>P95 500-1000ms:</strong> Acceptable but monitor. Consider reducing load for better UX.</li>
                    <li><strong>P95 &gt; 1000ms:</strong> Too slow. Reduce conversations, turns, or max_tokens in next test.</li>
                    <li><strong>Speedup &gt; 3x:</strong> Excellent caching! Multi-turn conversations work well.</li>
                    <li><strong>Speedup &lt; 2x:</strong> Poor caching. Check if context is too large or model supports caching.</li>
                </ul>
            </div>
        </div>

        <!-- Next Steps -->
        <div class="section">
            <h2>Next Steps</h2>

            <div class="config-grid">
                <div class="config-item">
                    <strong>Pre-Event Validation</strong>
                    <span style="font-size: 0.9em;">
                        {% if benchmark_p95 != 'N/A' and benchmark_p95 | float < 500 %}
                        âœ“ Ready for workshop
                        {% else %}
                        Reduce attendee count or optimize
                        {% endif %}
                    </span>
                </div>
                <div class="config-item">
                    <strong>Model Comparison</strong>
                    <span style="font-size: 0.9em;">Order with different model to compare P95 and Speedup</span>
                </div>
                <div class="config-item">
                    <strong>Load Testing</strong>
                    <span style="font-size: 0.9em;">Increase conversations to find capacity limits</span>
                </div>
                <div class="config-item">
                    <strong>Re-run Test</strong>
                    <span style="font-size: 0.9em;">Destroy and re-order with adjusted parameters</span>
                </div>
            </div>
        </div>

        <!-- Raw Output -->
        <div class="section">
            <h2>Full Benchmark Output</h2>
            <pre class="raw-output">{{ benchmark_output_raw }}</pre>
        </div>

        <!-- Footer -->
        <div class="footer">
            <div>LiteMaaS Benchmark Report</div>
            <div class="timestamp">Generated: {{ report_timestamp }}</div>
        </div>
    </div>
</body>
</html>
